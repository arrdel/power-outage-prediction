{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77264534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tsl.data.spatiotemporal_dataset import SpatioTemporalDataset\n",
    "from tsl.ops.connectivity import SparseTensor\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_undirected\n",
    "from pathlib import Path\n",
    "path = \"/home/jaydenfassett/amlproject/data/county_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2efbaf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path)\n",
    "graph = pd.read_csv(\"/home/jaydenfassett/amlproject/data/geographic/graph.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "071796f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing index\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Re-run notebook if index is in cols",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounty\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalizing\u001b[39m\u001b[38;5;124m\"\u001b[39m,col)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-run notebook if index is in cols\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m (df[col] \u001b[38;5;241m-\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m      9\u001b[0m grouped \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounty\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Re-run notebook if index is in cols"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.reset_index()\n",
    "# mean 0, var 1 all feature columns\n",
    "\n",
    "for col in df.columns.drop(labels=[\"level\", \"county\", \"datetime\"]):\n",
    "    print(\"Normalizing\",col)\n",
    "    assert col != \"index\", \"Re-run notebook if index is in cols\"\n",
    "    df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\n",
    "grouped = df.groupby(['level', 'county']).first().reset_index()\n",
    "uniques = grouped.columns.drop(labels=[\"level\",\"county\"])\n",
    "times = grouped['level'].unique()\n",
    "nodes = grouped['county'].unique()\n",
    "\n",
    "fips_idx = {name: i for i, name in enumerate(nodes)} # FIPS CODE / local index map.\n",
    "\n",
    "T, N, F = len(times), len(nodes), len(uniques) - 1\n",
    "features = grouped[[i for i in uniques]].values\n",
    "\n",
    "datetimes = features[:,0].reshape(T, N)\n",
    "tensor_3d = features[:,1:].reshape(T, N, F).astype(np.float32)\n",
    "\n",
    "# t, n, f = tensor_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27a268bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['src','dest']:\n",
    "    graph[col] = graph[col].apply(lambda x: fips_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "372a5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(tensor_3d)\n",
    "\n",
    "E = torch.from_numpy(graph[['src','dest']].values).T\n",
    "# E = tuple(graph[['src','dest']].values.T)\n",
    "\n",
    "E_w = torch.from_numpy(graph[\"total_voltage\"].values)\n",
    "\n",
    "E_w = (E_w - E_w.mean()) / E_w.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3c1e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpatioTemporalDataset(\n",
    "    tensor_3d,                    \n",
    "    mask=None,                    \n",
    "    connectivity=(E,E_w),    # Takes edges & weights    \n",
    "    horizon=1,                    \n",
    "    window=3,                     \n",
    "    stride=1,                     \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72d51511",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(\"/home/jaydenfassett/amlproject/data/tsldataset\")\n",
    "savepath.mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "dataset.save(savepath / \"dataset.tsl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "powerup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
